{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import callbacks\n",
    "from keras import layers, models, regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# giving directory path to data set\n",
    "dataset_path='/content/drive/MyDrive/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=(65,65)\n",
    "# data_generator = ImageDataGenerator(rescale=1./255)\n",
    "data_generator=ImageDataGenerator(rescale=1./255,rotation_range=20,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,validation_split=0.2)\n",
    "train_dataset=data_generator.flow_from_directory(dataset_path,target_size=image_size,batch_size=32,class_mode='binary',shuffle=True,subset=\"training\")\n",
    "validation_dataset=data_generator.flow_from_directory(dataset_path,target_size=image_size,batch_size=32,class_mode='binary',shuffle=True,subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu',padding=\"same\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu',padding=\"same\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3),activation='relu',padding=\"same\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128,activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64,activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping=callbacks.EarlyStopping(monitor=\"accuracy\",mode=\"max\",patience=3,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset,epochs=15,batch_size=32,validation_data=validation_dataset,callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Haar cascade classifiers for face and eye detection. You may download it from OpenCV2 github repo\n",
    "face=cv2.CascadeClassifier('/content/haarcascade_frontalface_default.xml')\n",
    "eye=cv2.CascadeClassifier('/content/haarcascade_eye_tree_eyeglasses.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration():\n",
    "    start_time=time.time()\n",
    "    end_time=start_time+0.7\n",
    "    open=0\n",
    "    closed=0\n",
    "    #This loop runs via function for 0.7 second as it is equal to twice the average required for human to blink. If the eye is closed for more than\n",
    "    #time person is possibly drowsie.\n",
    "    while(time.time()<end_time):\n",
    "        ret,frame=video_capture.read()\n",
    "        if(ret==True):\n",
    "            gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)   # Convert the frame to grayscale as model is trained on gray scale images\n",
    "            faces=face.detectMultiScale(gray)             # Detect faces\n",
    "            for (x,y,w,h) in faces:                       # Iterate over the detected faces\n",
    "                roi_gray=gray[y:y+h,x:x+w]                # Get the region of interest containing the face in gray scale image\n",
    "                roi_color=frame[y:y+h,x:x+w]              # Get the region of interest containing the face in colored image\n",
    "                eyes=eye.detectMultiScale(roi_gray)       # Detect eyes in the ROI\n",
    "                for (a,b,c,d) in eyes:                    #Iterate over the detected faces\n",
    "                    eye_roi_gray=roi_gray[b:b+d,a:a+c]    # Get the region of interest containing the eye in grey scale image\n",
    "                    eye_roi_color=roi_color[b:b+d,a:a+c]  # Get the region of interest containing the eye in colored image\n",
    "                    eye_image=eye_roi_gray.copy()         #Creating an image out of the eye_roi_grey for further process\n",
    "                    #Processing the image according to requirments of the model\n",
    "                    resized_frame=cv2.resize(eye_image,(65,65))\n",
    "                    normalized_frame=resized_frame/255.0\n",
    "                    flattened_frame=normalized_frame.flatten()\n",
    "                    #Predicting eyes condition open or closed\n",
    "                    predictions=model.predict(flattened_frame)\n",
    "                    if(predictions==0):\n",
    "                        closed=closed+1\n",
    "                    elif(predictions==1):\n",
    "                        open=open+1\n",
    "    return open,closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_capture=cv2.VideoCapture(0)\n",
    "if(video_capture.isOpened()):\n",
    "    #This loop runs for the time the vehicle is on. It can beforcefully shut by pressing 'q' or any command as possible. The manufacturer\n",
    "    #can apply the optimal condition\n",
    "    while(True):\n",
    "        open,closed=duration(open,closed)\n",
    "        if(open>=1.05*closed):\n",
    "            print(\"Normal\")               # Normal.No action required\n",
    "        elif(open>=0.3*closed):\n",
    "            print(\"notification\")         #Insert a code to issue a notificatio or confirmation prompt\n",
    "        elif(open<3*closed):\n",
    "            print(\"alarm\")                #Insert a code to ring an alarm\n",
    "\n",
    "        #The above choosen value are custom and calculated by self estimation.\n",
    "        #This can be changed according to users preference\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "else:\n",
    "    print(\"Camera is closed. Try giving other camera index in videocapture\")\n",
    "video_capture.release()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
